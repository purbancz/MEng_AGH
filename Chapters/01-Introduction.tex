\chapter[Particle Swarm Optimization (PSO)]{\acrfull{pso}}
\label{cp:introduction}

{
% \parindent0pt


\nocite{eberhart1995new}
\acrfull{pso}
% \acrshort{pso} \acrlong{pso}
is 
a meta-heuristic \glslink{metaheuristic} algorithm
% an evolutionary computational model
introduced by \citet{kennedy1995particle} and inspired by the social behavior and synchronous movement of groups of organisms.

\section{%Conceptual
Origins and Motivation}
% The authors of the particle swarm concept identify three primary sources of inspiration.
The development of the particle swarm paradigm was shaped by inspiration from several domains.
Firstly,
the
conceptual
origins of the
model
% particle swarm concept
trace back to early computational simulations aimed at visualizing the coordinated movement of animal formations, such as herds, flocks of birds or schools of fish.
% Particle swarm concept, introduced by \citet{kennedy1995particle},
In referencing early influences on their work, Kennedy and Eberhart point to the simulations of bird flocking developed by \citet{reynolds1987flocks} and by \citet{heppner1990stochastic}. Reynolds, motivated by the aesthetic beauty of 
graceful and erratic choreography of a bird flock,
% flocking behavior,
and Heppner, a zoologist interested in the biological mechanisms behind coordinated group movement, both explored how large numbers of birds could maneuver synchronously---suddenly shifting direction, dispersing, and regrouping with apparent ease. These researchers shared a key insight: that such complex and seemingly unpredictable collective behavior could emerge from simple, local processes,
and primitive rules,
such as those modeled using systems like cellular automata.
% , provided a conceptual foundation for understanding how decentralized, self-organizing systems might be applied in computational models---an idea central to the development of Particle Swarm Optimization.

Beyond the aesthetic and biological insights, these simulations carried the implicit suggestion that such models could extend to more abstract domains, including human social and cognitive behavior. Drawing on observation that individuals in animal groups can benefit from shared information \parencite{wilson1975sociobiology}, \citeauthor{kennedy1995particle} proposed that similar mechanisms might underlie information exchange and adaptation in human social contexts. Unlike animals constrained by physical proximity and collision avoidance, humans operate in a multidimensional socio-cognitive space, adjusting beliefs, attitudes, and knowledge in response to peers. This abstraction allows for modeling human-like adaptation without the constraints of physical movement.



During the initial simplification of the original paradigm, it became obvious that the behavior of the agent population resembles rather a \textit{swarm} than a flock. The term was adopted from \citet{millonas1993swarms}, who introduced early models of swarm intelligence within the context of artificial life (e-life) and identified five foundational principles underlying swarm behavior. Notably, \acrshort{pso} adheres to all five of these principles.
Similarly, the other part of the optimizer's name was selected as a compromise as that the entities used in the model have neither mass nor volume, and thus could be called \textit{points}. The authors decide to use this term \textit{particle}, because it had already started to be used in computer graphics to simulate scattered or fuzzy phenomena like smoke, fire, and clouds \citep{reeves1983particle}.


Last but not least, in their another seminal paper, \citet{eberhart1995new} highlight that, in addition to the aforementioned artificial life methodology, \acrlong{pso} also has its roots in the field of evolutionary computation. Specifically, they note that \acrshort{pso}, on the ground of conceptual foundations, shares important similarities with \acrfull{ga}, \acrfull{es}, and \acrfull{ep}.

While it was evident from the very beginning that both approaches are similar in their parallel processing nature and share the core principle of population-based search and stochastic exploration, early researchers quickly recognized several important distinctions. Most notably,  \acrshort{ga} and \acrshort{es} employ a ``competitive'' strategy: individuals in the population compete for survival, and poorly performing solutions are replaced by offspring generated through variation operators such as crossover and mutation. In contrast, \acrshort{pso} operates on a ``cooperative'' principle with a velocity-driven update mechanism grounded in behavioral modeling, which allows for smoother, memory-informed trajectories through the search space. A more thorough philosophical and empirical comparison between PSO and GA is provided by \citet{angeline1998evolutionary}.

% Within this framework, the PSO algorithm emerged not merely as a visual simulation of flocking, but as a conceptual tool for modeling social learning and adaptation. Particles, conceived as collision-free agents, navigate an abstract solution space, adjusting their positions based on both individual experience and the shared knowledge of the group. Thus, PSO embodies a synthesis of biological modeling, social theory, and computational optimization, grounded in the principle that simple, local rules can drive complex, adaptive behavior in both natural and artificial systems.




\section{Principles}




% \section{Formal Setup}




In general, the \acrfull{pso} method can be described as:
\begin{equation}\label{eq:pso}
(P', \vec{b}_g') = m(P, \vec{b_g}, f),
\end{equation}
where \(P\) denotes a multiset---referred to as the \textit{swarm}---containing positions in the \gls{search-space}, with each element representing a solution candidate termed \textit{particle}.
% Each particle evaluates the \textit{objective function} \(f\)  at its current location,
% The function \(f\) is the \textit{objective function} used to evaluate each particle,
The function \(f\) is the \textit{objective function} that particles evaluate at their current locations.
The vector \(\vec{b_g}\) denotes the best solution found by the swarm so far, that is, the position corresponding to the lowest (or highest, depending on the optimization goal) value of the objective function \(f\).
In a \(d\)-dimensional \gls{search-space} \(\vec{b_g} = (b_{g}^{1}, b_{g}^{2}, \dots, b_{g}^{d}) \).
The function \(m\)~is a stochastic operator that governs how the swarm evolves, i.e., how particles move within the search space, defined by the equations~\eqref{eq:velocity_update}--\eqref{eq:gbest_update} below.
%
In line with common practice and terminology borrowed from the field of evolutionary computation, the terms swarm, particles, and objective function are often interchangeably referred to as population, individuals, and fitness function, respectively.

% In a \(d\)-dimensional \gls{search-space},
Each particle is represented by a tuple:
\begin{equation}\label{eq:particle}
X_i = \langle \vec{x_i}, \vec{v_{i}}, \vec{b_i} \rangle,
\end{equation}
where \(\vec{x_i}\) is the particle's position vector, i.e. a set of coordinates describing particle location in \gls{search-space},
% , i.e. a set of coordinates describing a point in space
\(\vec{x_i} = (x_{i}^{1}, x_{i}^{2}, \dots, x_{i}^{d})\). Each particle is also associated with a velocity vector, \(\vec{v_i} =\allowbreak\ (v_{i}^{1}, v_{i}^{2},\dots, v_{i}^{d})\) and retains a personal best position, 
\(\vec{b_i} = (b_{i}^{1}, b_{i}^{2}, \dots, b_{i}^{d}) \).



These terms are used to determine the movement of the particles, which is effectively guided by the following equations:
\begin{equation}\label{eq:velocity_update}
% \forall_{j \in \{ 1,\ldots,d \}}
v_{i}^{j}{}'= \underbrace{\omega v_{i}^{j}}_{\text{inertia}} +
\underbrace{c_1 r_1 (b_{i}^{j} - x_{i}^{j})}_{\text{cognitive component}} +
\underbrace{c_2 r_2 (b_{g}^{j} - x_{i}^{j})}_{\ \ \text{social component}\ \ }
\end{equation}
\begin{equation}\label{eq:position_update}
% \forall_{j \in \{ 1,\ldots,d \}}
x_{i}^{j}{}' = x_{i}^{j} + v_{i}^{j}{}',
\end{equation}
where $\omega$ is the \textit{inertia} weight, \(c_1\) and \(c_2\) are acceleration coefficients (sometimes called \textit{cognitive} and \textit{social} coefficients, respectively), \(r_1\) and \(r_2\) are random values uniformly distributed in the range [0, 1], and the equations are applied to each dimension  $j \in \{ 1,\ldots,d \}$.

The velocity update equation preserves momentum from the previous direction while steering each particle toward its personal best and the global best positions, thereby promoting convergence to the best known solution over successive iterations.

\begin{figure}[H]
    \centering
    \begin{tikzpicture}[
    % scale=1.2,
    point_style/.style={circle, fill=black, inner sep=1.5pt},
    vector_style/.style={-Latex, thick},
    label_style/.style={font=\small},
    component_label_style/.style={font=\footnotesize, sloped, midway},
    guide_line_style/.style={dashed, gray!60, thin}
    ]
    
    % --- Define Coordinates ---
    % Current particle position
    \coordinate (xi_t) at (0,0);
    
    % Personal best and Global best positions
    \coordinate (pbest_i) at (2.2,2.7);
    \coordinate (gbest) at (8,0.5);
    
    % --- Component vectors (as displacements) ---
    \coordinate (inertia_vec) at (0.9, -1.2);
    
    % Cognitive component: c1 * r1 * (p_best,i(t) - x_i(t))
    \coordinate (cognitive_vec_raw) at ($(pbest_i) - (xi_t)$);
    \coordinate (cognitive_vec) at ($1.4*(cognitive_vec_raw)$); % Scaled for visualization
    
    % Social component: c2 * r2 * (g_best(t) - x_i(t))
    \coordinate (social_vec_raw) at ($(gbest) - (xi_t)$);
    \coordinate (social_vec) at ($0.5*(social_vec_raw)$); % Scaled for visualization
    
    % --- Calculate New Velocity and Position ---
    \coordinate (v_tip1) at ($(xi_t) + (inertia_vec) + (cognitive_vec) + (social_vec)$);
    \coordinate (xi_t_plus_1) at (v_tip1); % Since v_i(t+1) is displacement from xi_t
    
    % --- Draw Points and Labels ---
    \node[point_style, label={[label_style]below left:$x_i$}] at (xi_t) {};
    \node[draw, cross out, inner sep=1.5pt, label={[label_style]above:$b_{i}$}] at (pbest_i) {};
    \node[draw, cross out, inner sep=1.5pt, label={[label_style]below right:$b_{g}$}] at (gbest) {};
    \node[circle, fill=black, inner sep=1.5pt, label={[label_style]above right:$x_i'$}] at (xi_t_plus_1) {};
    
    % --- Draw Guide Lines (to pbest and gbest) ---
    \draw[guide_line_style] (xi_t) -- (pbest_i);
    \draw[dash dot, gray!60, thin] (xi_t) -- (gbest);
    
    % --- Draw Resultant New Velocity ---
    \draw[vector_style, ultra thick, opacity=0.5] (xi_t) -- node[component_label_style, below, near end] {${v}_i'$} (v_tip1);
    
    % --- Draw Velocity Components (Tip-to-Tail for clarity) ---
    % 1. Inertia component
    \draw[vector_style, densely dotted] (xi_t) -- node[component_label_style, above] {$\omega v_{i}$} ($(xi_t) + (inertia_vec)$) coordinate (tip_inertia);
    
    % 2. Cognitive component (starting from tip of inertia)
    \draw[vector_style, dashed] (tip_inertia) -- node[component_label_style, above, near end] {$c_1 r_1 (p_{i} - x_{i})$} ($(tip_inertia) + (cognitive_vec)$) coordinate (tip_cognitive);
    
    % 3. Social component (starting from tip of cognitive)
    \draw[vector_style, dash dot] (tip_cognitive) -- node[component_label_style, above] {$c_2 r_2 (p_{g} - x_{i})$} ($(tip_cognitive) + (social_vec)$) coordinate (tip_social);

    \end{tikzpicture}
    \caption[Geometric illustration of PSO's position and velocity update]{Geometric 2-dimensional illustration of a single particle's position and velocity update in PSO.}
    \label{fig:PSO_geometric_illustration}
\end{figure}

The objective function defines a total order over the set of candidate solutions, allowing the algorithm to continuously identify and update the personal and global best positions throughout the search process. Each particle thus keeps track of its own historical best position, and is influenced by the global best position, 
\(\vec{b_g}\), found so far by the entire swarm.
\begin{equation}\label{eq:pbest_update}
\vec{b}_i' =
\begin{cases}
\vec{x}_i', & \text{if } f(\vec{x}_i') \leq f(\vec{b}_i) \\
\vec{b}_i, & \text{otherwise,}
\end{cases}
\end{equation}
\begin{equation}\label{eq:gbest_update}
\vec{b}_g' = \arg\min_{{\vec{b}_i'}\ \mid\ X_i' \in P'} f(\vec{b}_i').
\end{equation}



The algorithm begins by initializing a population of particles, each representing a candidate solution, randomly sampled within the defined bounds of the \gls{search-space}. In parallel, initial velocity vectors are randomly assigned to each particle. The fitness of each particle is then evaluated using the objective function, allowing the assignment of each particle's personal best position. The best-performing particle among the entire swarm establishes the initial global best position.

Following initialization, the swarm enters an iterative optimization loop. In each iteration, particle velocities and positions are updated according to the above-mentioned equations \eqref{eq:velocity_update} and \eqref{eq:position_update}. After the movement step, each particle's new position is evaluated, and personal and global bests are updated if improvements are observed.


This iterative process---of evaluating fitness, updating velocities and positions, and tracking and adjusting towards the best solutions---continues until a predefined termination criterion is met.
Upon completion, the global best position discovered by any particle during the process is returned as the algorithm's final solution.

\vspace{.935em}

\begin{algorithm}[H]
\caption{Particle Swarm Optimization (PSO)}\label{alg:pso}
% \caption{PSO}
\KwIn{Swarm size \(N\), acceleration coefficients \(c_1\) and \(c_2\), inertia weight \(\omega\)}
\KwOut{Best solution found}
Initialize population of \(N\) particles with random positions and velocities\;
Evaluate the fitness of each particle\;
Set global best position \(b_g\), for each particle set personal best position \(b_i\)\;
    \While{Termination criterion is not met}{
        Modify each particle's position and velocity by equations (\ref{eq:velocity_update}) and (\ref{eq:position_update})\;
        Evaluate the fitness of each particle\;
        Update the personal best \(b_i\) and global best \(b_g\) positions if necessary\;        
    }
\Return The global best position \(b_g\) as the final solution\;
\end{algorithm}

\vspace{.935em}

At its core, \acrshort{pso} mimics the social dynamics of a group of entities---i.e., particles---that explore the admissible space of solutions by adjusting their trajectories  based on both individual experience and shared information within the swarm. In consequence, the particle swarm is more than a mere collection of independent agents---a single particle, in isolation, is not capable to solve the problem. Progress emerges only through interaction and mutual influence among particles. Thus, problem-solving is a collective phenomenon, arising from the continuous exchange of information and the responses it triggers within the population \citep{poli2007particle}.

% \begin{figure}[!htbp]
%   \centering

%   % Manually define the frame numbers you want to include:
%   \foreach \n in {0000,0005,0010,0015,0020,0025,0030,0035,0040,0045,0050,0055} {
%     \begin{subfigure}{0.329\textwidth}
%       \centering
%       \includegraphics[width=\linewidth]{Figures/AlgorithmsAnimations/PSO/PSO_Rastrigin_with_arrows_frame_\n.png}
%       \caption*{Frame \n}
%     \end{subfigure}%
%     \ifnum\n=0010 \par\fi
%     \ifnum\n=0025 \par\fi
%     \ifnum\n=0040 \par\fi
%     \ifnum\n=0055 \par\fi
%   }

%   \caption{Selected frames of PSO on Rastrigin function (4×3 grid).}
%   \label{fig:pso-raster-grid}
% \end{figure}



\section{Key Components and Parameters}

\subsection{Swarm Size}

The swarm size \( \lvert P\mkern1mu\rvert = N \), as denoted in the Algorithm \ref{alg:pso} above, refers to the number of particles (or solution candidates) used by the algorithm.  Intuitively, a larger number of particles increases the initial diversity of the swarm—assuming a uniform initialization scheme—and may improve the probability of discovering high-quality solutions in a fewer number of steps. However, larger swarms also raise the computational cost per iteration, since the number of objective function evaluations per step scales linearly with the swarm size. Conversely, smaller swarms reduce this cost but may suffer from premature convergence, limited exploration, or failure to reach the global optimum.

While swarms in nature can number in the thousands or even millions, PSO has been proven to work surprisingly well with relatively small populations. Earlier studies claim that swarm sizes in the range of 20 to 50 particles are commonly used in practice \citep{poli2007particle}. Some authors report effective performance with even smaller swarms---10 to 30 particles---and successful applications have been documented with fewer than 10 particles under specific conditions \citep{engelbrecht2007computational, vandenbergh2002analysis}. However, more recent literature suggests that while small swarm sizes remain widely used, they are not optimal for efficiently solving complex or multimodal optimization problems. For such tasks, swarm sizes in the range of 70 to 500 particles have been found to offer better performance \citep{abualigah2025particle}.

Ultimately, the optimal swarm size is problem-dependent, varying with characteristics of the objective landscape such as smoothness, modality, or dimensionality. It is commonly treated as a tunable hyperparameter, often adjusted through empirical calibration or automated tuning procedures. In the experiments presented in \autoref{cp:experiment}, the swarm size has been excluded from parameter tuning and was fixed at \( N = 100 \) for all PSO variants tested across all benchmark problems.


\subsection{Inertia}

Lipsum

\subsection{Cognitive Component}

Lipsum

\subsection{Social Component}

Lipsum

\subsection{Repair Algorithm}

Lipsum

\subsection{Termination Criterion}

Lipsum


% - velocity components (and coefficients)
% - termination criterion
% - repair algorithm (bounce, clip, reinitialize)
% - early variants (Local Best PSO)


\section{Applications}

Optimization is a fundamental task across numerous scientific, engineering, and industrial domains, involving the determination of the best values for a set of parameters to satisfy some measure of optimality, often subject to certain constraints. \Glspl{optimization-problem}  can vary significantly in their characteristics, including whether the variables are continuous or discrete, if constraints are present, the nature of the objective function (e.g., linear, non-linear, unimodal, multimodal), and the dimensionality of the \gls{search-space}.
Particle Swarm Optimization has emerged as a powerful and versatile metaheuristic for addressing a broad spectrum of such challenges. A central strength of PSO lies in its ability to operate without requiring gradient information, making it particularly useful for problems where derivatives are unavailable, unreliable, or costly to compute.

Shortly after the original formulation of the algorithm, a binary variant was introduced \citep{kennedy1997discrete}, extending PSO to discrete search spaces by interpreting particle velocities as probabilities of bit flips, typically using a sigmoid transformation. 
It was also adapted to multi-objective optimization, giving rise to a family of MOPSO algorithms designed to approximate Pareto-optimal fronts for problems with conflicting objectives \citep{alvarezbenitez2005mopso, nebro2009smpsomcdm, shao2025improved}.


Even though the experiments presented in \autoref{cp:experiment} of this study focus primarily on the set of selected complex, single-objective, real-valued benchmark problems—spanning unconstrained, multivariate, non-linear, unimodal and multimodal, as well as derivative and non-derivative scenarios---the literature offers numerous examples of PSO being applied to real-world optimization tasks. Due to its versatility and effectiveness across diverse problem types, PSO has found successful application in a wide range of fields, including
electrical and electronic engineering \citep[e.g.,][]{jin2024improved, salvatierra2024pso, dibya2025optimized},
automation and control systems \citep[e.g.,][]{duan2024using,urgan2024pso,gil2024platooning}, 
communication theory \citep[e.g.,][]{qiao2025resource,jin2024overview,jin2025design}, 
operations research \citep[e.g.,][]{li2025ore,omran2025empirical,dong2022optimized, palaniappan2025task, simaiya2024hybrid}, 
mechanical and civil engineering \citep[e.g.,][]{ramkumar2025intelligent,wang2025optimisation,houssein2025recent}, 
energy systems \citep[e.g.,][]{bade2025multi,zhang2024energy,hamza2024optimization}, 
biomedical engineering \citep[e.g.,][]{mallik2024swarm}, 
data mining \citep[e.g.,][]{shan2024research,zuo2024knowledge,carstensen2025efficient}, 
machine learning \citep[e.g.,][]{alenezi2025hybrid,balavani2024enhanced,tijjani2024enhanced}, 
robotics \citep[e.g.,][]{sharma2025swarm,liu2025design,prakash2024swarm}, 
and many other domains. 





\section{Variants}





\section{Problems}


% Welcome to the \textcolor{maincolor}{\textit{IPLeiria Thesis}} template! Thank you for choosing it for your dissertation, reports, or other projects. This template reflects countless hours of development and learning, and I hope you enjoy using it as much as I enjoyed creating it. This chapter introduces the motivation behind the template and guides you through the initial steps to start using it. In \autoref{cp:user-guide}, you will find a comprehensive guide to fully utilise the template, and \autoref{cp:latex-tutorial} provides a concise \LaTeX~tutorial to help you maximise its capabilities. Happy reading and future writing!

% %%%%%%%%%%%%%%%%%%%%%
% I've known \LaTeX~since 2020, and since then, I have been using it constantly for a wide variety of purposes. Over time, I've used and reviewed more than a hundred templates, and there is always something missing. \textit{Always}. If a template is powerful -- \textit{i.e.}, it has many options and is highly customisable -- it's often not well-organised. Conversely, if it is well-organised, it usually lacks flexibility and customisation options. Some templates even compile with numerous errors and warnings. Most importantly, the majority are not very user-friendly. For these reasons, I decided to create my own template for theses and reports, specifically tailored for the Polytechnic University of Leiria. Throughout this project, I focused on achieving four key goals: \(i)\) creating a template that is organised and well-structured in terms of file organisation, \(ii)\) ensuring it is clean yet aesthetically pleasing and professional, \(iii)\) making it customisable to suit different needs, and \(iv)\) designing it to be user-friendly, especially for newcomers.

% \section{Getting Started}
% To start using this template, you first need to know how to use \LaTeX. For this, please refer to \autoref{cp:latex-tutorial}. Once you are familiar with \LaTeX, you will need to either install it locally or use an online \LaTeX~editor.

% If you prefer an online editor, I highly recommend \href{https://www.overleaf.com/}{Overleaf}. While Overleaf offers a paid subscription for extended compilation time, this template is specifically designed to compile within the limits of the free subscription plan. To use the template in Overleaf, just refer to \href{https://www.overleaf.com/latex/templates/unofficial-polytechnic-university-of-leiria-estg-thesis-slash-report-template/tqgbrncfhwgt}{official template page} and click \textit{Use as Template}. But if you prefer to use a different version of it (which I do not recommend), you can do the following:

% \begin{enumerate}[font=\itshape]
%     \setlength{\itemsep}{.375em}
%     \item \textit{Download the \href{https://github.com/joseareia/ipleiria-thesis/releases}{desired version} from the GitHub repository as a Zip file.}
%     \item \textit{Login to your Overleaf account.}
%     \item \textit{In your Project area, click in the menu and then: New Project \(\to\) Upload Project.}
%     \item \textit{Upload the Zip file.}
%     \item \textit{Let Overleaf compile the document.}
% \end{enumerate}

% If you choose to use a local editor, you must first install \LaTeX~on your machine. For this, there are several options, but I personally recommend either \href{https://www.tug.org/texlive/}{TeX-Live} or \href{https://miktex.org/}{MikTeX}. After installing \LaTeX, you will need to select an editor for writing and editing your documents. To help with this decision, I suggest checking out this helpful \href{https://tex.stackexchange.com/questions/339/latex-editors-ides}{post}, which provides a comprehensive overview of various editors you can use. Once \LaTeX~and your editor are set up, simply clone or download the \href{https://github.com/joseareia/ipleiria-thesis/releases}{latest} version of the template from GitHub and start using it!

% \begin{block}[tip]
% \textit{Within the official GitHub repository, you will find a \href{https://github.com/joseareia/ipleiria-thesis/blob/master/Makefile}{Makefile} and a \href{https://github.com/joseareia/ipleiria-thesis/blob/master/.latexmkrc}{Latexmk} configuration file, both of which can be used to compile this project. The Makefile utilises \texttt{rubber} as the compiler and has a dependency of \texttt{inotify-tools}. Feel free to use whichever option best suits your needs.}
% \end{block}

% \section{Getting Help}
% As a newcomer, you may encounter situations where you want to do something in \LaTeX~or with this template but aren't sure how. When questions arise, you have several options. First, you can read the wiki available in the \href{https://github.com/joseareia/ipleiria-thesis}{GitHub} repository for this template. Another great option is the \href{https://tex.stackexchange.com/}{TeX Stack Exchange}, an active community that can help with nearly any issue. Of course, Google is always a reliable resource. If all else fails, feel free to contact me directly with any questions about the template. You can reach me at \textit{\textcolor{blue}{\myuline{jose.apareia@gmail.com}}}.

% \subsection{Issues, Feature Request and Suggestions}
% If, by any chance, you encounter a bug, have a suggestion, or would like to request a feature, you can submit them via the \textit{Issues} tab in the \href{https://github.com/joseareia/ipleiria-thesis}{GitHub} repository. Please be as descriptive as possible when reporting issues, and make sure to provide the appropriate labels to help me triage them effectively.

% For feature requests or suggestions, you can either follow the steps mentioned above or, if you prefer, you can implement the feature yourself and submit a pull request. Both pull requests and pushes trigger a \href{https://github.com/joseareia/ipleiria-thesis/actions/workflows/latex.yml}{GitHub Action} that will automatically compile the document. If the compilation fails, the pull request will be automatically rejected. Please keep this in mind and take care when submitting changes.

% \subsection{In-Built Comments, Guidance Texts and Warnings}
% Within this document template, you may encounter informational text displaying the message ``Writing Guidance.'' These sections are provided solely as guidance to help users understand what content should be included in specific sections. They are not related to the \LaTeX~code itself within this template.

% While navigating through the template, especially the configuration files, you will notice that everything is thoroughly commented. \LaTeX~can sometimes be difficult to understand without proper documentation for the packages we are working with. With that in mind, I have made an effort to comment on all the changes I've made. Occasionally, I may forget or deem it unnecessary to comment on simpler changes, but more advanced modifications are always accompanied by detailed comments.

% Finally, regarding warnings: please take them into consideration when compiling the document. As you may have noticed, the template is designed to be free of warnings, so please strive to maintain this clean compilation.

% \section{Important Notices}
% Although this template is specifically tailored for students from all six schools of the Polytechnic University of Leiria, you are welcome to use it if you are from a different institution. It is highly customisable and can be easily modified to suit the needs of other schools. If your school is interested in adopting this as the official template, please contact me first. 

% If you decide to use this template, please consider acknowledging it in your work. To do so, simply cite it using \verb|\citep{IPLeiriaThesis}|. You can also show your appreciation for this template by giving a \href{https://github.com/joseareia/ipleiria-thesis/stargazers}{star} on the GitHub repository. This helps increase its visibility, and you will receive notifications about the latest updates and releases. Either way, acknowledging this work, which involved significant effort and countless hours, would be greatly appreciated.




}