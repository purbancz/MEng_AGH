\chapter[Particle Swarm Optimization (PSO)]{\acrfull{pso}}
\label{cp:pso}

{
% \parindent0pt


\nocite{eberhart1995new}
\acrfull{pso}
% \acrshort{pso} \acrlong{pso}
is 
a meta-heuristic \glslink{metaheuristic} algorithm
% an evolutionary computational model
introduced by \citet{kennedy1995particle} and inspired by the social behavior and synchronous movement of groups of organisms.

\section{%Conceptual
Origins and Motivation}
% The authors of the particle swarm concept identify three primary sources of inspiration.
The development of the particle swarm paradigm was shaped by inspiration from several domains.
Firstly,
the
conceptual
origins of the
model
% particle swarm concept
trace back to early computational simulations aimed at visualizing the coordinated movement of animal formations, such as herds, flocks of birds or schools of fish.
% Particle swarm concept, introduced by \citet{kennedy1995particle},
In referencing early influences on their work, Kennedy and Eberhart point to the simulations of bird flocking developed by \citet{reynolds1987flocks} and by \citet{heppner1990stochastic}. Reynolds, motivated by the aesthetic beauty of 
graceful and erratic choreography of a bird flock,
% flocking behavior,
and Heppner, a zoologist interested in the biological mechanisms behind coordinated group movement, both explored how large numbers of birds could maneuver synchronously---suddenly shifting direction, dispersing, and regrouping with apparent ease. These researchers shared a key insight: that such complex and seemingly unpredictable collective behavior could emerge from simple, local processes,
and primitive rules,
such as those modeled using systems like cellular automata.
% , provided a conceptual foundation for understanding how decentralized, self-organizing systems might be applied in computational models---an idea central to the development of Particle Swarm Optimization.

Beyond the aesthetic and biological insights, these simulations carried the implicit suggestion that such models could extend to more abstract domains, including human social and cognitive behavior. Drawing on observation that individuals in animal groups can benefit from shared information \parencite{wilson1975sociobiology}, \citeauthor{kennedy1995particle} proposed that similar mechanisms might underlie information exchange and adaptation in human social contexts. Unlike animals constrained by physical proximity and collision avoidance, humans operate in a multidimensional socio-cognitive space, adjusting beliefs, attitudes, and knowledge in response to peers. This abstraction allows for modeling human-like adaptation without the constraints of physical movement.



During the initial simplification of the original paradigm, it became obvious that the behavior of the agent population resembles rather a \textit{swarm} than a flock. The term was adopted from \citet{millonas1993swarms}, who introduced early models of swarm intelligence within the context of artificial life (e-life) and identified five foundational principles underlying swarm behavior. Notably, \acrshort{pso} adheres to all five of these principles.
Similarly, the other part of the optimizer's name was selected as a compromise as that the entities used in the model have neither mass nor volume, and thus could be called \textit{points}. The authors decide to use this term \textit{particle}, because it had already started to be used in computer graphics to simulate scattered or fuzzy phenomena like smoke, fire, and clouds \citep{reeves1983particle}.


Last but not least, in their another seminal paper, \citet{eberhart1995new} highlight that, in addition to the aforementioned artificial life methodology, \acrlong{pso} also has its roots in the field of evolutionary computation. Specifically, they note that \acrshort{pso}, on the ground of conceptual foundations, shares important similarities with \acrfull{ga}, \acrfull{es}, and \acrfull{ep}.

While it was evident from the very beginning that both approaches are similar in their parallel processing nature and share the core principle of population-based search and stochastic exploration, early researchers quickly recognized several important distinctions. Most notably,  \acrshort{ga} and \acrshort{es} employ a ``competitive'' strategy: individuals in the population compete for survival, and poorly performing solutions are replaced by offspring generated through variation operators such as crossover and mutation. In contrast, \acrshort{pso} operates on a ``cooperative'' principle with a velocity-driven update mechanism grounded in behavioral modeling, which allows for smoother, memory-informed trajectories through the \gls{search-space}. A more thorough philosophical and empirical comparison between PSO and GA is provided by \citet{angeline1998evolutionary}.

% Within this framework, the PSO algorithm emerged not merely as a visual simulation of flocking, but as a conceptual tool for modeling social learning and adaptation. Particles, conceived as collision-free agents, navigate an abstract solution space, adjusting their positions based on both individual experience and the shared knowledge of the group. Thus, PSO embodies a synthesis of biological modeling, social theory, and computational optimization, grounded in the principle that simple, local rules can drive complex, adaptive behavior in both natural and artificial systems.




\section{Principles}




% \section{Formal Setup}




In general, the PSO method can be described as:
\begin{equation}\label{eq:pso}
(P', \vec{b}_g') = m(P, \vec{b_g}, f),
\end{equation}
where \(P\) denotes a multiset---referred to as the \textit{swarm}---containing positions in the \gls{search-space}, with each element representing a solution candidate termed \textit{particle}.
% Each particle evaluates the \textit{objective function} \(f\)  at its current location,
% The function \(f\) is the \textit{objective function} used to evaluate each particle,
The function \(f\) is the \textit{objective function} that particles evaluate at their current locations.
The vector \(\vec{b_g}\) denotes the best solution found by the swarm so far, that is, the position corresponding to the lowest (or highest, depending on the optimization goal) value of the objective function \(f\).
In a \(d\)-dimensional \gls{search-space} \(\vec{b_g} = (b_{g}^{1}, b_{g}^{2}, \dots, b_{g}^{d}) \).
The function \(m\)~is a stochastic operator that governs how the swarm evolves, i.e., how particles move within the \gls{search-space}, defined by the equations~\eqref{eq:velocity_update}--\eqref{eq:gbest_update} below.
%
In line with common practice and terminology borrowed from the field of evolutionary computation, the terms swarm, particles, and objective function are often interchangeably referred to as population, individuals, and fitness function, respectively.

% In a \(d\)-dimensional \gls{search-space},
Each particle is represented by a tuple:
\begin{equation}\label{eq:particle}
X_i = \langle \vec{x_i}, \vec{v_{i}}, \vec{b_i} \rangle,
\end{equation}
where \(\vec{x_i}\) is the particle's position vector, i.e. a set of coordinates describing particle location in \gls{search-space},
% , i.e. a set of coordinates describing a point in space
\(\vec{x_i} = (x_{i}^{1}, x_{i}^{2}, \dots, x_{i}^{d})\). Each particle is also associated with a velocity vector, \(\vec{v_i} =\allowbreak\ (v_{i}^{1}, v_{i}^{2},\dots, v_{i}^{d})\) and retains a personal best position, 
\(\vec{b_i} = (b_{i}^{1}, b_{i}^{2}, \dots, b_{i}^{d}) \).



These terms are used to determine the movement of the particles, which is effectively guided by the following equations:
\begin{equation}\label{eq:velocity_update}
% \forall_{j \in \{ 1,\ldots,d \}}
v_{i}^{j}{}'= \underbrace{\omega v_{i}^{j}}_{\text{inertia}} +
\underbrace{c_1 r_1 (b_{i}^{j} - x_{i}^{j})}_{\text{cognitive component}} +
\underbrace{c_2 r_2 (b_{g}^{j} - x_{i}^{j})}_{\ \ \text{social component}\ \ }
\end{equation}
\begin{equation}\label{eq:position_update}
% \forall_{j \in \{ 1,\ldots,d \}}
x_{i}^{j}{}' = x_{i}^{j} + v_{i}^{j}{}',
\end{equation}
where $\omega$ is the \textit{inertia} weight, \(c_1\) and \(c_2\) are acceleration coefficients (sometimes called \textit{cognitive} and \textit{social} coefficients, respectively), \(r_1\) and \(r_2\) are random values uniformly distributed in the range [0, 1], and the equations are applied to each dimension  $j \in \{ 1,\ldots,d \}$.

The velocity update equation preserves momentum from the previous direction while steering each particle toward its personal best and the global best positions, thereby promoting convergence to the best known solution over successive iterations.

\begin{figure}[H]
    \centering
    \begin{tikzpicture}[
    % scale=1.2,
    point_style/.style={circle, fill=black, inner sep=1.5pt},
    vector_style/.style={-Latex, thick},
    label_style/.style={font=\small},
    component_label_style/.style={font=\footnotesize, sloped, midway},
    guide_line_style/.style={dashed, gray!60, thin}
    ]
    
    % --- Define Coordinates ---
    % Current particle position
    \coordinate (xi_t) at (0,0);
    
    % Personal best and Global best positions
    \coordinate (pbest_i) at (2.2,2.7);
    \coordinate (gbest) at (8,0.5);
    
    % --- Component vectors (as displacements) ---
    \coordinate (inertia_vec) at (0.9, -1.2);
    
    % Cognitive component: c1 * r1 * (p_best,i(t) - x_i(t))
    \coordinate (cognitive_vec_raw) at ($(pbest_i) - (xi_t)$);
    \coordinate (cognitive_vec) at ($1.4*(cognitive_vec_raw)$); % Scaled for visualization
    
    % Social component: c2 * r2 * (g_best(t) - x_i(t))
    \coordinate (social_vec_raw) at ($(gbest) - (xi_t)$);
    \coordinate (social_vec) at ($0.5*(social_vec_raw)$); % Scaled for visualization
    
    % --- Calculate New Velocity and Position ---
    \coordinate (v_tip1) at ($(xi_t) + (inertia_vec) + (cognitive_vec) + (social_vec)$);
    \coordinate (xi_t_plus_1) at (v_tip1); % Since v_i(t+1) is displacement from xi_t
    
    % --- Draw Points and Labels ---
    \node[point_style, label={[label_style]below left:$x_i$}] at (xi_t) {};
    \node[draw, cross out, inner sep=1.5pt, label={[label_style]above:$b_{i}$}] at (pbest_i) {};
    \node[draw, cross out, inner sep=1.5pt, label={[label_style]below right:$b_{g}$}] at (gbest) {};
    \node[circle, fill=black, inner sep=1.5pt, label={[label_style]above right:$x_i'$}] at (xi_t_plus_1) {};
    
    % --- Draw Guide Lines (to pbest and gbest) ---
    \draw[guide_line_style] (xi_t) -- (pbest_i);
    \draw[dash dot, gray!60, thin] (xi_t) -- (gbest);
    
    % --- Draw Resultant New Velocity ---
    \draw[vector_style, ultra thick, opacity=0.5] (xi_t) -- node[component_label_style, below, near end] {${v}_i'$} (v_tip1);
    
    % --- Draw Velocity Components (Tip-to-Tail for clarity) ---
    % 1. Inertia component
    \draw[vector_style, densely dotted] (xi_t) -- node[component_label_style, above] {$\omega v_{i}$} ($(xi_t) + (inertia_vec)$) coordinate (tip_inertia);
    
    % 2. Cognitive component (starting from tip of inertia)
    \draw[vector_style, dashed] (tip_inertia) -- node[component_label_style, above, near end] {$c_1 r_1 (b_{i} - x_{i})$} ($(tip_inertia) + (cognitive_vec)$) coordinate (tip_cognitive);
    
    % 3. Social component (starting from tip of cognitive)
    \draw[vector_style, dash dot] (tip_cognitive) -- node[component_label_style, above] {$c_2 r_2 (b_{g} - x_{i})$} ($(tip_cognitive) + (social_vec)$) coordinate (tip_social);

    \end{tikzpicture}
    \caption[Geometric illustration of PSO's position and velocity update]{Geometric 2-dimensional illustration of a single particle's position and velocity update in PSO.}
    \label{fig:PSO_geometric_illustration}
\end{figure}

The objective function defines a total order over the set of candidate solutions, allowing the algorithm to continuously identify and update the personal and global best positions throughout the search process. Each particle thus keeps track of its own historical best position, and is influenced by the global best position, 
\(\vec{b_g}\), found so far by the entire swarm.
\begin{equation}\label{eq:pbest_update}
\vec{b}_i' =
\begin{cases}
\vec{x}_i', & \text{if } f(\vec{x}_i') \leq f(\vec{b}_i) \\[6pt]
\vec{b}_i, & \text{otherwise,}
\end{cases}
\end{equation}
\begin{equation}\label{eq:gbest_update}
\vec{b}_g' = \arg\min_{{\vec{b}_i'}\ \mid\ X_i' \in P'} f(\vec{b}_i').
\end{equation}



The algorithm begins by initializing a population of particles, each representing a candidate solution, randomly sampled within the defined bounds of the \gls{search-space}. In parallel, initial velocity vectors are randomly assigned to each particle. The fitness of each particle is then evaluated using the objective function, allowing the assignment of each particle's personal best position. The best-performing particle among the entire swarm establishes the initial global best position.

Following initialization, the swarm enters an iterative optimization loop. In each iteration, particle velocities and positions are updated according to the above-mentioned equations \eqref{eq:velocity_update} and \eqref{eq:position_update}. After the movement step, each particle's new position is evaluated, and personal and global bests are updated if improvements are observed.


This iterative process---of evaluating fitness, updating velocities and positions, and tracking and adjusting towards the best solutions---continues until a predefined termination criterion is met.
Upon completion, the global best position discovered by any particle during the process is returned as the algorithm's final solution.

\vspace{.935em}

\begin{algorithm}[H]
\caption{Particle Swarm Optimization (PSO)}\label{alg:pso}
% \caption{PSO}
\KwIn{Swarm size \(N\), acceleration coefficients \(c_1\) and \(c_2\), inertia weight \(w\)}
\KwOut{Best solution found}
Initialize population of \(N\) particles with random positions and velocities\;
Evaluate the fitness of each particle\;
Set global best position \(b_g\), for each particle set personal best position \(b_i\)\;
    \While{Termination criterion is not met}{
        Modify each particle's position and velocity by equations (\ref{eq:velocity_update}) and (\ref{eq:position_update})\;
        Evaluate the fitness of each particle\;
        Update the personal best \(b_i\) and global best \(b_g\) positions if necessary\;        
    }
\Return The global best position \(b_g\) as the final solution\;
\end{algorithm}

\vspace{.935em}

At its core, \acrshort{pso} mimics the social dynamics of a group of entities---i.e., particles---that explore the admissible space of solutions by adjusting their trajectories  based on both individual experience and shared information within the swarm. In consequence, the particle swarm is more than a mere collection of independent agents---a single particle, in isolation, is not capable to solve the problem. Progress emerges only through interaction and mutual influence among particles. Thus, problem-solving is a collective phenomenon, arising from the continuous exchange of information and the responses it triggers within the population \citep{poli2007particle}.

% \begin{figure}[!htbp]
%   \centering

%   % Manually define the frame numbers you want to include:
%   \foreach \n in {0000,0005,0010,0015,0020,0025,0030,0035,0040,0045,0050,0055} {
%     \begin{subfigure}{0.329\textwidth}
%       \centering
%       \includegraphics[width=\linewidth]{Figures/AlgorithmsAnimations/PSO/PSO_Rastrigin_with_arrows_frame_\n.png}
%       \caption*{Frame \n}
%     \end{subfigure}%
%     \ifnum\n=0010 \par\fi
%     \ifnum\n=0025 \par\fi
%     \ifnum\n=0040 \par\fi
%     \ifnum\n=0055 \par\fi
%   }

%   \caption{Selected frames of PSO on Rastrigin function (4×3 grid).}
%   \label{fig:pso-raster-grid}
% \end{figure}



\section{Key Components and Parameters}

\subsection{Swarm Size}

The swarm size \( \lvert P\mkern1mu\rvert = N \), as denoted in the Algorithm \ref{alg:pso} above, refers to the number of particles (or solution candidates) used by the algorithm.  Intuitively, a larger number of particles increases the initial diversity of the swarm—assuming a uniform initialization scheme—and may improve the probability of discovering high-quality solutions in a fewer number of steps. However, larger swarms also raise the computational cost per iteration, since the number of objective function evaluations per step scales linearly with the swarm size. Conversely, smaller swarms reduce this cost but may suffer from premature convergence, limited exploration, or failure to reach the global optimum.

While swarms in nature can number in the thousands or even millions, PSO has been proven to work surprisingly well with relatively small populations. Earlier studies claim that swarm sizes in the range of 20 to 50 particles are commonly used in practice \citep{poli2007particle}. Some authors report effective performance with even smaller swarms---10 to 30 particles---and successful applications have been documented with fewer than 10 particles under specific conditions \citep{engelbrecht2007computational, vandenbergh2002analysis}. However, more recent literature suggests that while small swarm sizes remain widely used, they are not optimal for efficiently solving complex or multimodal \glspl{optimization-problem}. For such tasks, swarm sizes in the range of 70 to 500 particles have been found to offer better performance \citep{abualigah2025particle}.

Ultimately, the optimal swarm size is problem-dependent, varying with characteristics of the objective landscape such as smoothness, modality, or dimensionality. It is commonly treated as a tunable hyperparameter, often adjusted through empirical calibration or automated tuning procedures. In the experiments presented in \autoref{cp:experiment}, the swarm size has been excluded from parameter tuning and was fixed at \( N = 100 \) for all PSO variants tested across all benchmark problems.


\subsection{Inertia Weight}

Inertia refers to the contribution of a particle's previous velocity to its current velocity update and acts as a memory term, sustaining previous trajcetories. If this influence were left unbounded, the algorithm would become unstable, often exhibiting oscillatory behavior with amplitudes increasing over successive iterations.
Historically, in the earliest implementations of PSO, the primary mechanism to control unstable, oscillating, and divergent particle trajectories and prevent velocities from ``exploding'' to large values was velocity clamping. This involved setting an upper bound ($v_{\text{max}}$) for the velocity components. If a particle's velocity exceeded this maximum in any dimension, it was simply truncated to $v_{\text{max}}$. Although velocity clamping helped limit excessive movement and supported global exploration, it introduced several challenges. The optimal value o $v_{\text{max}}$ was highly problem-dependent and difficult to tune. Moreover, clamping did not guarantee convergence, and often led to particles bouncing along or becoming clipped to the boundaries of the \gls{search-space}.

To address these limitations, the \textit{inertia weight}, $\omega$, was introduced by \citeauthor{shi1998modified} \parencite*{shi1998modified,shi1999empirical}. This parameter directly scales the contribution of the particle's previous velocity to its current velocity update. It governs how much of the particle's current velocity is retained in the next iteration. Intuitively, higher inertia weight values promote exploration by allowing particles to move more freely across the \gls{search-space}. However, if too large, it can cause the swarm to diverge or overshoot optimal solutions.
Lower values  enhances exploitation by reducing the particle's acceleration, allowing for finer, local searches around promising areas.  Extremely low values can limit the swarm's exploration ability, leading to premature convergence or stagnation in local optima.

\citet{clerc2002particle} introduced the constriction coefficient $\chi$ as an alternative to the inertia weight, also aimed at controlling swarm dynamics and ensuring convergence. Although their formulations differ, a PSO with a constriction coefficient is algebraically equivalent to a PSO with an inertia weight. This means that, properly tuned, both approaches can achieve similar performance and guarantee convergence without the need for arbitrary $v_{\text{max}}$ clamping. Despite their theoretical equivalence, the inertia-weight formulation has become the more widely adopted approach in the literature and remains the standard in most contemporary PSO implementations.

The choice of $\omega$ must be made in conjunction with the acceleration coefficients, $c_1$ and $c_2$. Theoretical studies have established conditions for guaranteed convergent particle trajectories. For a simplified PSO system
\begin{equation}
   1 > \omega > \frac{1}{2}(c_1 + c_2) - 1 \geq 0 
\end{equation}
ensures convergence to an equilibrium state \citep{vandenbergh2006study,trelea2003particle}.
This condition is critical for understanding when a particle's trajectory will converge, diverge, or exhibit cyclic behavior. These studies also show the sets of parameters that lead to divergent or oscillating trajectories.

While most PSO implementations used a static (constant) inertia weight, dynamic strategies have also been widely adopted to optimize performance across different stages of the search. Common strategies include decreasing $\omega$ from a high initial value to a lower final value either linearly
\citep[e.g.,][]{zheng2003convergence,guan2022improved}
or non-linearly \citep[e.g.,][]{naka2002hybrid,chen2006natural}, 
random selection of $\omega$ \citep[e.g.,][]{lin2019hybrid,fauzi2023inertia},
adjustment controlled by fuzzy logic \citep[e.g.,][]{shi2001fuzzy, nobile2018fuzzy}
and many others, including performance-based adaptation \citep[e.g.,][]{borowska2017nonlinear,zhang2023elite}.

In this study, a static inertia weight is employed. The value of 
$\omega$
 is tuned jointly with the acceleration coefficients 
$c_1$ and $c_2$
  for each PSO variant tested.

% In the present study, a static inertia weight is employed. The value of 
% $\omega$
%  is tuned jointly with the acceleration coefficients 
% $c_1$ and $c_2$
%   for each PSO variant tested, as described in the experimental section in \autoref{cp:experiment}.




\subsection{Acceleration Coefficients}

\subsubsection{Cognitive Component}\label{subsubsec:cog_comp}

The cognitive component embodies an individual particle's experiential knowledge---sometimes interpreted as a form of self-reflection. It encourages a particle to return towards its own personal best position, $b_i$, found since the search began. This inherent pull towards a particle's historical success is mathematically represented by one of the components in the velocity update equation \eqref{eq:velocity_update}:
\begin{equation}
\texttt{std}_\text{cog} = c_1 r_1 (b_{i}^{j} - x_{i}^{j})
\label{eq:std_cog_component}
\end{equation}
where, as previously introduced, $x_i$ is the particle's current position, $b_i$ is the best position the $i$-th particle has discovered so far, $r_1$ is a uniformly distributed random number in [0, 1], and $c_1$ is the \textit{cognitive acceleration coefficient}.

Intuitively, the cognitive component, by directing particles towards their individual best solutions, primarily facilitates local search and exploitation within the particle's discovered vicinity.
The cognitive acceleration coefficient ($c_1$) acts as a ``confidence parameter'', quantifying the degree to which a particle trusts its own personal best experience. 

\subsubsection{Social Component}

The social component represents the collective or shared knowledge within the swarm. It encourages a particle to move towards the global best position found by any particle in the entire swarm. This attraction to a ``group norm'' or ``standard'' is a core tenet of PSO's sociological inspiration. Mathematically, it appears in another part of particle's velocity update equation  \eqref{eq:velocity_update}:
\begin{equation}
\texttt{std}_\text{soc} = c_2 r_2 (b_{g}^{j} - x_{i}^{j})
\label{eq:std_soc_component}
\end{equation}
where, as previously explained, $x_i$ is the particle's current position, $b_g$ is the global best position found by the swarm up to current iteration, $r_2$ is a random number sampled from a uniform distribution between 0 and 1, and $c_2$ is the \textit{social acceleration coefficient}.

Intuitively, the social component primarily facilitates global search and exploration. It pulls particles towards the most successful areas identified collectively, fostering the propagation of good solutions throughout the swarm. The social acceleration coefficient $c_2$ acts as a ``trust parameter'' that quantifies how much confidence a particle places in its peers' or group success.

\subsubsection{Parameter Selection}\label{subsubsec:param_select}
% \vspace{.935em}

The value of $c_1$ and $c_2$ critically influences the balance between exploration and exploitation in the PSO algorithm.
\begin{itemize}
    \item If $c_1$ is significantly larger than $c_2$, particles are more strongly attracted to their own personal best positions, which can lead to ``excessive wandering'' or an inefficient exploration of new global areas, as particles may get stuck focusing only on their individual paths without sufficient pull towards the global optimum.
    Conversely, if $c_1 = 0$, particles rely solely on the social component, turning the entire swarm into a single stochastic hill-climber attracted to one point ($b_g$).
    \item If $c_2$ is significantly larger than $c_1$, particles are more strongly attracted to the global best position, which can cause them to rush prematurely towards optima, potentially leading to premature convergence if the $b_g$ is a local minimum.
    Conversely, if $c_2 = 0$, particles will rely solely on their individual best positions, reducing the swarm's overall exploratory ability and potentially leading to suboptimal solutions. In such model, there would be no interaction between particles.
\end{itemize}
One should keep in mind that, as with the inertia weight, poor initialization of $c_1$ and $c_2$ may also lead to divergent and oscillatory behavior of the swarm \citep[][]{engelbrecht2007computational}. Further discussion, comparative analysis and extensions of social-only and cognitive-only models can be found in \citep[][]{kennedy1997particle,brits2002niching,liu2019hierarchical,chen2025multi}.

In most PSO implementations, the acceleration coefficients are typically maintained at constant values throughout the optimization process. This convention also followed in the present study. Nonetheless, several alternative strategies  have been proposed in the literature.
% These include dynamically adjusting one or both coefficients during the run \citep[e.g.,][]{ratnaweera2002pso,watanabe2024nonlinear,tian2024improved}, adapting them to the current state of the swarm
% \citep[e.g.,][]{zhan2007adaptive,wang2011selfadaptive,wang2018hybrid,bonthagorla2025fast}, or binding one to the other via a functional relationship \citep[e.g.,][]{cleghorn2022particle,yin2023reinforcement}.
These include schemes that dynamically adjust the coefficients during the optimization run \citep[e.g.,][]{ratnaweera2002pso,watanabe2024nonlinear,tian2024improved}, approaches that adapt the coefficients based on the swarm's current state or performance indicators \citep[e.g.,][]{zhan2007adaptive,wang2011selfadaptive,wang2018hybrid,bonthagorla2025fast},
setting them at random \citep[e.g.,][]{krohling2004gaussian},
or coupling one coefficient through functional relationship with the other \citep[e.g.,][]{cleghorn2022particle,yin2023reinforcement}.

% In the literature the most common strategy is to keep the acceleration coefficient constant and this is the approach taken in this study. However, there are some implementations that implement dynamic  \citep[e.g.,][]{} or adaptive strategies \citep[e.g.,][]{} or bind one coefficient in relationship with the other \citep[e.g.,][]{}.

% As with the inertia weight, poor initialization of $c_1$ and $c_2$ may lead to divergent and oscillatory behavior of the swarm. 





\subsection{Boundary Management}

In PSO, particles, which represent candidate solutions, traverse a multidimensional \gls{search-space} based on their own best-found positions (personal best or $b_i$) and the overall swarm's best-found position (global best or $b_g$). During this iterative movement, particularly due to the velocity update mechanisms, particles can sometimes exceed the predefined boundaries of the \gls{search-space}. Such boundary violations are problematic because they can lead to particles exploring infeasible regions, diverging uncontrollably from the optimization task, or causing computational errors if the objective function is undefined outside its specified domain. To address this, various \textit{repair methods} or \textit{boundary handling techniques} have been developed to manage particles that approach or cross these boundaries, aiming to maintain search integrity, ensure solution feasibility, and effectively balance exploration and exploitation.

Key repair and boundary handling mechanisms are listed below. Some of them are PSO-specific, others are characteristic to any population-based optimization algorithm.

\subsubsection{Absorption}
    
        If a particle’s position exceeds a boundary, it is confined by projecting it back to the nearest valid point within the defined \gls{search-space}. This process---commonly referred to as boundary clamping (or, in some contexts, clipping)---involves replacing the violating coordinate with its nearest feasible boundary value. Formally, for each dimension $j$:
    \begin{equation}
        x_{i}^{j}{}' \leftarrow \min(\max(x_{i}^{j}{}', x_{\min}^{j}), x_{\max}^{j}),
    \end{equation}
    where $x_{\min}$ and $x_{\max}$ stand for the lower and upper bounds for dimension $j$, respectively.
    This method applies not only to continuous variables but can also be adapted for discrete variables (by rounding to the nearest valid integer), or even combinatorial problems (by adjusting to satisfy unique coordinate requirements).
    
\subsubsection{Reflection}
    When a particle's proposed position exceeds a boundary, its excess displacement is reversed---in effect, the position is reflected across the bound. 
Additionally, in my implementation, the velocity is reversed and damped, depending on how many times it being reflected, mimicking elastic bouncing behavior.
% Formally, suppose a coordinate $x_{i}^{j}{}'$ crosses the lower or upper bound for dimension $j$:
% \begin{equation}
% x_{i}^{j}{}' = 
% \begin{cases}
% x_{\min}^{j} + \Delta, & \text{if } n \bmod 2 = 0, \\[6pt]
% x_{\max}^{j} - \Delta, & \text{if } n \bmod 2 = 1,
% \end{cases}
% \end{equation}
% where
% \begin{equation}
% \Delta = \lvert x_{i}^{j}{}' - x_{\min}^{j} \rvert \bmod r^j, \quad 
% n = \left\lfloor \frac{ \lvert x_{i}^{j}{}' - x_{\min}^{j} \rvert }{ r^j } \right\rfloor, \quad
% r^j = x_{\max}^{j} - x_{\min}^{j}.
% \end{equation}
% An analogous rule applies when exceeding the upper bound by redefining the excess relative to $x_{\max}^{j}$.
% 
% Additionally, the corresponding velocity component is reversed in sign and damped based on the number of bounces to prevent perpetual boundary oscillations:
% 
% \begin{equation}
% v_{i}^{j}{}' = 
% \begin{cases}
% -\, |v_{i}^{j}{}'| \cdot \gamma, & \text{if reflected}, \\[6pt]
% |v_{i}^{j}{}'| \cdot \gamma, & \text{otherwise},
% \end{cases}
% \quad 0 < \gamma < 1.
% \end{equation}
% Here, $\gamma$ is a random or fixed damping factor that reduces kinetic energy with each bounce.
% 
% This reflection approach effectively handles multiple crossings by repeatedly folding the position back into the feasible interval, ensuring smooth constraint enforcement without abrupt clamping.
This method allows particles to remain dynamically active near the boundaries while preventing them from escaping the \gls{search-space}.

\subsubsection{Penalization}
    Instead of modifying the position directly, the objective function is augmented with a penalty term that discourages infeasible solutions by reducing their fitness \citep[see, e.g.,][]{parsopoulos2002particle}.
% \subsubsection{Rejection (Unconfined Repair)}% (maybe one-word term with -ion suffix - rejection?)\\
\subsubsection{Exclusion}
    This method allows particles to temporarily ``roam'' into infeasible space before being implicitly  ``repaired.''  \citet{hu2002solving} proposed an approach where $b_i$ and $b_g$ are updated only if the current position is better and violates no constraints, ensuring that both values always remain feasible.
    Invalid particles are then implicitly pulled back towards the feasible space over time. This prevents infeasible information from propagating through the swarm and influencing the swarm’s trajectory.  
    % \begin{equation}
    %     \vec{b}_i' =
    %     \begin{cases}
    %     \vec{x}_i', & \text{if } f(\vec{x}_i') \le f(\vec{b}_i) 
    %     \ \text{and} \ 
    %     \forall_j x_{\min}^j \le x_i^{j}{}' \le x_{\max}^j, \\[6pt]
    %     \vec{b}_i, & \text{otherwise}.
    %     \end{cases}
    % \end{equation}
    % \begin{equation}
    %     \vec{b}_g' = 
    %     \arg\min_{
    %     \substack{
    %     \forall_j x_{\min}^j \le b_i^{j}{}' \le x_{\max}^j,
    %     }
    %     }
    %     f(\vec{b}_i').
    % \end{equation}
    % This strategy
    It 
    % can enhance exploration near the edges of the feasible hypercube of solutions but
    is most effective when the proportion of infeasible particles remains low; if too many particles are infeasible, swarm diversity may be insufficient to cover the \gls{search-space} adequately.
% \subsubsection{Cancellation}
%     Components that cause boundary violations are disregarded in the velocity update, effectively canceling their influence.
% \subsubsection{Reversion}
%     A violating component can be replaced by its opposite, possibly scaled by a damping coefficient, to redirect the particle back into the feasible region \citep[cf.][]{clerc2006particle}.
\subsubsection{Transposition}
    In some designs---especially for periodic or toroidal \glspl{search-space}---a particle that exits one boundary re-enters from the opposite side. This is analogous to wrap-around or tiling in numerical simulations.
\subsubsection{Reinitialization}
    Replacing infeasible particles with new randomly generated positions from the \gls{search-space}. This approach may be beneficial in cases where the feasible space is made up of a number of disjointed regions. The strategy will allow particles to cross boundaries of one feasible region to explore another feasible region.
\subsubsection{Relocation}
     \citet{elgallad2002enhancing}  proposed replacing an infeasible particle’s position  with their last feasible personal best.

\vspace{.935em}


In practice, boundary handling often includes additional choices regarding the particle's velocity. Upon repair, the velocity can be preserved, reversed, reset to zero, or reinitialized. For an in-depth discussion and empirical comparisons of boundary handling methods in PSO, see \citep{chu2011handling} and \citep{padhye2013boundary}.

While boundary handling is fundamental for maintaining solution feasibility and preventing uncontrolled divergence, overly rigid methods can prematurely restrict the \gls{search-space}, potentially leading to entrapment in suboptimal local minima. Conversely, allowing controlled, transient excursions into infeasible regions can sometimes enhance the algorithm's global search capability, particularly in problems characterized by complex or disconnected feasible spaces. Effective boundary management is thus inherently problem-dependent and often requires careful tuning and empirical validation.
In this study, the absorption method is employed (without modifying the velocity). Preliminary tests done during parameter tuning indicated that this approach produced more stable and reliable results across all tested PSO variants, at least when comparing it with reflection and reinitialization.


\subsection{Termination Criteria}

In the context of stochastic optimization algorithms, termination criteria are essential mechanisms that determine when the iterative search process should conclude. The design of these criteria critically influences the algorithm’s efficiency and the quality of the solutions obtained. The overarching goal is to halt the optimization either when a sufficiently good solution has been found or when further computational effort is unlikely to produce meaningful improvement.

Termination strategies can be broadly categorized into direct criteria and adaptive, convergence-based methods that detect stagnation.

\subsubsection{Direct Criteria}

Direct criteria are simple, predefined stopping rules, commonly used due to their ease of implementation and general applicability.

% \begin{description}
%     \item[Maximum Number of Iterations or Function Evaluations] 
%     This is the most widely adopted and pragmatic stopping condition. The algorithm runs for a specified maximum number of iterations or until a predefined limit of fitness function evaluations is reached. This ensures consistent computational budgets across experiments. Both parameters are mutually definable via swarm size $N$ value. While straightforward, this approach does not guarantee solution quality: an insufficient budget can cause premature termination before convergence, whereas an excessive limit can waste computational resources after stagnation.

%     \item[Acceptable Solution Found]

%     This criterion terminates the search once a particle's fitness reaches a predefined acceptable error threshold 
%     $\epsilon$ of a known optimum $f(x^*)$, i.e.,
%     \begin{equation}
%         f(x_i) \le | f(x^*) - \epsilon |.
%     \end{equation}
%     This method directly addresses the optimization objective. However, it requires prior knowledge of the optimal value, which is often unavailable in real-world problems unless the optimum is a known value (e.g., zero for neural network training). Moreover, selecting an appropriate $\epsilon$ is non-trivial---a large value can lead to suboptimal solutions, while a very narrow tolerance may prevent termination entirely, especially for basic PSO variants that struggle with fine-grained refinement.
% \end{description}

\paragraph{Maximum number of iterations or function evaluations}
This is the most widely adopted and pragmatic stopping condition employed also in this study. The algorithm runs for a specified maximum number of iterations 
or until a predefined limit of fitness function evaluations is reached. This ensures consistent computational budgets across experiments. These parameters are mutually definable via the swarm size $N$.
While straightforward, this approach does not guarantee solution quality: an insufficient budget can cause premature termination before convergence, whereas an excessive limit can waste computational resources after stagnation.

\paragraph{Acceptable solution found}
This criterion terminates the search once a particle's fitness reaches a predefined acceptable error threshold 
$\epsilon$ of a known optimum $f(x^*)$, i.e.,
\begin{equation}
    f(x_i) \le | f(x^*) - \epsilon |.
\end{equation}
This method directly addresses the optimization objective. However, it requires prior knowledge of the optimal value, which is often unavailable in real-world problems unless the optimum is a known value (e.g., zero for neural network training). Moreover, selecting an appropriate $\epsilon$ is non-trivial---a large value can lead to suboptimal solutions, while a very narrow tolerance may prevent termination entirely, especially for basic PSO variants that struggle with fine-grained refinement.

\subsubsection{Adaptive Criteria (Stagnation Detection)}

Adaptive criteria monitor the swarm’s behavior during the run to detect stagnation---that is, loss of meaningful progress or exploration ability.

\paragraph{Improvement monitoring}

This general principle involves tracking the improvement metrics over a sliding window of iterations. If no significant change is observed, the swarm is deemed to have stagnated. The improvement can be measured by average change in particle positions or velocity---if approaches zero, it indicates that the swarm is making minimal progress.
The other improvement metric is the relative change in the global best fitness:
\begin{equation}
      f' = \frac{f(b_g') - f(b_g)}{f(b_g)}.
\end{equation}
If this ``slope'' falls below a small threshold for a consistent number of iterations, it suggests that the swarm is no longer making significant progress and has likely converged to a local minimum. This method is considered superior to position-based methods because it directly assesses progress based on the fitness landscape. However, its main drawback is the risk of premature termination if some particles are still actively exploring distant, potentially better regions of the \gls{search-space}. Therefore, it is often recommended to use the objective function slope in conjunction with position-based swarm diversity monitoring methods (like swarm radius or clustering) to ensure that all particles have converged before stopping. 


\paragraph{Swarm diversity monitoring} Swarm diversity can be quantified using spatial spread or clustering around the global best. One approach is to compute the normalized swarm radius---a near-zero radius indicates that particles have clustered tightly around $b_g$, suggesting convergence. An alternative is particle clustering, which defines a neighborhood around $b_g$ and counts how many particles lie within a specified distance. If the proportion of particles in this cluster exceeds a threshold (e.g., 60\% of the swarm), the swarm is considered converged.
Both approaches can complement improvement monitoring to detect stagnation and avoid unnecessary computation once convergence is evident.

\paragraph{}

% It is important to distinguish between theoretical convergence and practical convergence in PSO literature. Early analyses showed that particle velocities and positions converge to an stable point under certain parameter settings. However, this point is not necessarily an optimum of the objective function—it simply indicates that particles have ceased moving. This phenomenon, known as premature convergence or stagnation, remains a well-known limitation: the swarm can settle in a local minimum or suboptimal region, failing to locate the global optimum unless additional diversification mechanisms or restarts are employed.

A critical distinction in PSO literature is between ``convergence to an equilibrium state'' and ``convergence to an optimum'' (local or global). Early theoretical analyses \citep[][]{vandenbergh2002analysis} focused on ensuring that particle trajectories would eventually converge to a fixed point in the \gls{search-space}. However, this ``equilibrium point'' is not guaranteed to be an actual optimum of the objective function---it merely signifies that the particles have stopped moving or clustered together. This inherent weakness, known as "premature convergence" or "stagnation," means the original PSO algorithm is not guaranteed to find a local (let alone global) minimum from an arbitrary initial state.


\section{Applications}

Optimization is a fundamental task across numerous scientific, engineering, and industrial domains, involving the determination of the best values for a set of parameters to satisfy some measure of optimality, often subject to certain constraints. \Glspl{optimization-problem}  can vary significantly in their characteristics, including whether the variables are continuous or discrete, if constraints are present, the nature of the objective function (e.g., linear, non-linear, unimodal, multimodal), and the dimensionality of the \gls{search-space}.
Particle Swarm Optimization has emerged as a powerful and versatile \gls{metaheuristic} for addressing a broad spectrum of such challenges. A central strength of PSO lies in its ability to operate without requiring gradient information, making it particularly useful for problems where derivatives are unavailable, unreliable, or costly to compute.

Shortly after the original formulation of PSO, its binary variant was introduced \citep{kennedy1997discrete}, extending  the algorithm to discrete \glspl{search-space} by interpreting particle velocities as probabilities of bit flips, typically using a sigmoid transformation. 
PSO was also adapted to multi-objective optimization, giving rise to a family of MOPSO \glspl{metaheuristic} designed to approximate Pareto-optimal fronts for problems with conflicting objectives \citep{alvarezbenitez2005mopso, nebro2009smpsomcdm, shao2025improved}.


Even though the experiments presented in \autoref{cp:experiment} of this study focus primarily on the set of selected complex, single-objective, real-valued benchmark problems—spanning unconstrained, multivariate, non-linear, unimodal and multimodal, as well as differentiable and non-differentiable scenarios---the literature offers numerous examples of PSO being applied to real-world optimization tasks. Due to its versatility and effectiveness across diverse problem types, PSO has found successful application in a wide range of fields, including
electrical and electronic engineering \citep[e.g.,][]{jin2024improved, salvatierra2024pso, dibya2025optimized},
automation and control systems \citep[e.g.,][]{duan2024using,urgan2024pso,gil2024platooning}, 
communication theory \citep[e.g.,][]{qiao2025resource,jin2024overview,jin2025design}, 
operations research \citep[e.g.,][]{li2025ore,omran2025empirical,dong2022optimized, palaniappan2025task, simaiya2024hybrid}, 
mechanical and civil engineering \citep[e.g.,][]{ramkumar2025intelligent,wang2025optimisation,houssein2025recent, hao2025composite}, 
energy systems \citep[e.g.,][]{bade2025multi,zhang2024energy,hamza2024optimization}, 
biomedical engineering \citep[e.g.,][]{mallik2024swarm}, 
data mining \citep[e.g.,][]{shan2024research,zuo2024knowledge,carstensen2025efficient}, 
machine learning \citep[e.g.,][]{alenezi2025hybrid,balavani2024enhanced,tijjani2024enhanced}, 
robotics \citep[e.g.,][]{sharma2025swarm,liu2025design,prakash2024swarm}, 
and many other domains. 





\section{Limitations}

Particle Swarm Optimization is particularly renowned for its elegant simplicity and ease of implementation, requiring only a handful of intuitive parameters and being easy to adapt to a particular problem. It also delivers fast convergence and computational efficiency, often finding high-quality solutions in fewer iterations and with smaller swarm sizes than many alternative \glspl{metaheuristic}. Crucially, PSO does not require gradient information, enabling it to tackle non-differentiable or simulation-based objective functions where traditional methods fail. Moreover, PSO’s decentralized, particle-based mechanism lends itself naturally to parallel and distributed implementations.

% Despite its widespread adoption, conceptual simplicity, and computational efficiency, PSO is not without its limitations.
% The performance and convergence behavior of PSO heavily depend on the careful selection and tuning of control parameters, including the inertia weight ($\omega$), cognitive coefficient ($c_1$), social coefficient ($c_2$). Improper tuning can lead to inefficient exploration, poor convergence, or excessive computational costs. For instance, a high inertia weight promotes global exploration, but if too high, it can lead to divergence or particles overshooting optimal regions. Conversely, a very low inertia weight encourages local exploitation but may result in premature convergence to local optima. The optimal values for these parameters are often problem-dependent, requiring extensive trial-and-error or cross-validation for specific applications.

% PSO also faces challenges when applied to high-dimensional search spaces, an issue often referred to as the "curse of dimensionality". As the number of decision variables (dimensions) increases, the search space expands exponentially, making it significantly more difficult for the algorithm to efficiently explore and locate optima. In such spaces, PSO's performance can deteriorate, with particles potentially spending too much time in unimodal regions rather than finding optimal solutions. While various niching techniques have been developed to locate multiple optima, their solution quality tends to fall sharply as the dimensionality of the problem increases.


Despite these advantages, PSO exhibits several well-documented limitations: 
parameter sensitivity,
challenges when applied to high-dimensional \glspl{search-space},
the inability to adapt to dynamic and noisy cases,
and the lack of a native mechanism for handling constraints
\citep[see,][]{abualigah2025particle},
but
one of the most significant shortcomings of PSO is its tendency towards premature convergence and stagnation in local optima. Premature convergence occurs when the swarm settles on a suboptimal solution before thoroughly exploring the entire \gls{search-space}. This issue is particularly pronounced in multimodal optimization problems, which feature multiple local minima, making it challenging for the swarm to escape local attraction basins and locate the true global optimum. The core of this problem lies in the inherent dynamics of PSO: when a particle's current position, its personal best, and the global best positions coincide, the velocity update equation can cause the particle's velocity to diminish to zero. This leads to a stagnant state where particles cease movement, even if the converged point is not a local or global minimum.

Moreover, PSO's ability to refine solutions in the late stages of the search rapidly diminish. As particles approach the equilibrium spot, their step sizes tend to decrease, and velocities can become very small, making further significant progress difficult. The traditional PSO lacks dynamically adjustable mechanisms to balance exploration and exploitation effectively just after initial stages, which can hinder the ultimate accuracy of the found solution or prolong the convergence time unnecessarily.


% These drawbacks, extensively documented in the literature, often necessitate modifications or hybridizations of the canonical algorithm to ensure robust and effective performance, particularly on complex optimization landscapes. There is a vast body of papers that report on numerous variants, modifications, and hybrid PSO-based algorithms.

These drawbacks, extensively documented in the literature, have driven extensive research into PSO variants, modifications, and hybrid algorithms, resulting in a vast literature of enhanced PSO-based methods tailored for robust and effective performance on complex optimization landscapes \citep[see,][]{thangaraj2011particle,zhang2015comprehensive,sengupta2019particle,jain2022Overview,minku2023introduction,abualigah2025particle,chauhan2025learning,urbanczyk2025sequential}. This thesis contributes to that body of work, providing modified PSO variants that explicitly address above-mentioned issues through novel learning and diversity-enhancing strategies.
% The goal of the thesis is twofold: 
% \begin{enumerate}
%     \item To propose and investigate various methods to enhance the exploration capabilities and population diversity of Particle Swarm Optimization.
%     \item To design, implement, and evaluate the hybridization of such strategies that effectively address these limitations, ultimately improving PSO’s performance on complex optimization problems.
% \end{enumerate}











% - velocity components (and coefficients)
% - termination criterion
% - repair algorithm (bounce, clip, reinitialize)
% - early variants (Local Best PSO)



% Welcome to the \textcolor{maincolor}{\textit{IPLeiria Thesis}} template! Thank you for choosing it for your dissertation, reports, or other projects. This template reflects countless hours of development and learning, and I hope you enjoy using it as much as I enjoyed creating it. This chapter introduces the motivation behind the template and guides you through the initial steps to start using it. In \autoref{cp:user-guide}, you will find a comprehensive guide to fully utilise the template, and \autoref{cp:latex-tutorial} provides a concise \LaTeX~tutorial to help you maximise its capabilities. Happy reading and future writing!

% %%%%%%%%%%%%%%%%%%%%%
% I've known \LaTeX~since 2020, and since then, I have been using it constantly for a wide variety of purposes. Over time, I've used and reviewed more than a hundred templates, and there is always something missing. \textit{Always}. If a template is powerful -- \textit{i.e.}, it has many options and is highly customisable -- it's often not well-organised. Conversely, if it is well-organised, it usually lacks flexibility and customisation options. Some templates even compile with numerous errors and warnings. Most importantly, the majority are not very user-friendly. For these reasons, I decided to create my own template for theses and reports, specifically tailored for the Polytechnic University of Leiria. Throughout this project, I focused on achieving four key goals: \(i)\) creating a template that is organised and well-structured in terms of file organisation, \(ii)\) ensuring it is clean yet aesthetically pleasing and professional, \(iii)\) making it customisable to suit different needs, and \(iv)\) designing it to be user-friendly, especially for newcomers.

% \section{Getting Started}
% To start using this template, you first need to know how to use \LaTeX. For this, please refer to \autoref{cp:latex-tutorial}. Once you are familiar with \LaTeX, you will need to either install it locally or use an online \LaTeX~editor.

% If you prefer an online editor, I highly recommend \href{https://www.overleaf.com/}{Overleaf}. While Overleaf offers a paid subscription for extended compilation time, this template is specifically designed to compile within the limits of the free subscription plan. To use the template in Overleaf, just refer to \href{https://www.overleaf.com/latex/templates/unofficial-polytechnic-university-of-leiria-estg-thesis-slash-report-template/tqgbrncfhwgt}{official template page} and click \textit{Use as Template}. But if you prefer to use a different version of it (which I do not recommend), you can do the following:

% \begin{enumerate}[font=\itshape]
%     \setlength{\itemsep}{.375em}
%     \item \textit{Download the \href{https://github.com/joseareia/ipleiria-thesis/releases}{desired version} from the GitHub repository as a Zip file.}
%     \item \textit{Login to your Overleaf account.}
%     \item \textit{In your Project area, click in the menu and then: New Project \(\to\) Upload Project.}
%     \item \textit{Upload the Zip file.}
%     \item \textit{Let Overleaf compile the document.}
% \end{enumerate}

% If you choose to use a local editor, you must first install \LaTeX~on your machine. For this, there are several options, but I personally recommend either \href{https://www.tug.org/texlive/}{TeX-Live} or \href{https://miktex.org/}{MikTeX}. After installing \LaTeX, you will need to select an editor for writing and editing your documents. To help with this decision, I suggest checking out this helpful \href{https://tex.stackexchange.com/questions/339/latex-editors-ides}{post}, which provides a comprehensive overview of various editors you can use. Once \LaTeX~and your editor are set up, simply clone or download the \href{https://github.com/joseareia/ipleiria-thesis/releases}{latest} version of the template from GitHub and start using it!

% \begin{block}[tip]
% \textit{Within the official GitHub repository, you will find a \href{https://github.com/joseareia/ipleiria-thesis/blob/master/Makefile}{Makefile} and a \href{https://github.com/joseareia/ipleiria-thesis/blob/master/.latexmkrc}{Latexmk} configuration file, both of which can be used to compile this project. The Makefile utilises \texttt{rubber} as the compiler and has a dependency of \texttt{inotify-tools}. Feel free to use whichever option best suits your needs.}
% \end{block}

% \section{Getting Help}
% As a newcomer, you may encounter situations where you want to do something in \LaTeX~or with this template but aren't sure how. When questions arise, you have several options. First, you can read the wiki available in the \href{https://github.com/joseareia/ipleiria-thesis}{GitHub} repository for this template. Another great option is the \href{https://tex.stackexchange.com/}{TeX Stack Exchange}, an active community that can help with nearly any issue. Of course, Google is always a reliable resource. If all else fails, feel free to contact me directly with any questions about the template. You can reach me at \textit{\textcolor{blue}{\myuline{jose.apareia@gmail.com}}}.

% \subsection{Issues, Feature Request and Suggestions}
% If, by any chance, you encounter a bug, have a suggestion, or would like to request a feature, you can submit them via the \textit{Issues} tab in the \href{https://github.com/joseareia/ipleiria-thesis}{GitHub} repository. Please be as descriptive as possible when reporting issues, and make sure to provide the appropriate labels to help me triage them effectively.

% For feature requests or suggestions, you can either follow the steps mentioned above or, if you prefer, you can implement the feature yourself and submit a pull request. Both pull requests and pushes trigger a \href{https://github.com/joseareia/ipleiria-thesis/actions/workflows/latex.yml}{GitHub Action} that will automatically compile the document. If the compilation fails, the pull request will be automatically rejected. Please keep this in mind and take care when submitting changes.

% \subsection{In-Built Comments, Guidance Texts and Warnings}
% Within this document template, you may encounter informational text displaying the message ``Writing Guidance.'' These sections are provided solely as guidance to help users understand what content should be included in specific sections. They are not related to the \LaTeX~code itself within this template.

% While navigating through the template, especially the configuration files, you will notice that everything is thoroughly commented. \LaTeX~can sometimes be difficult to understand without proper documentation for the packages we are working with. With that in mind, I have made an effort to comment on all the changes I've made. Occasionally, I may forget or deem it unnecessary to comment on simpler changes, but more advanced modifications are always accompanied by detailed comments.

% Finally, regarding warnings: please take them into consideration when compiling the document. As you may have noticed, the template is designed to be free of warnings, so please strive to maintain this clean compilation.

% \section{Important Notices}
% Although this template is specifically tailored for students from all six schools of the Polytechnic University of Leiria, you are welcome to use it if you are from a different institution. It is highly customisable and can be easily modified to suit the needs of other schools. If your school is interested in adopting this as the official template, please contact me first. 

% If you decide to use this template, please consider acknowledging it in your work. To do so, simply cite it using \verb|\citep{IPLeiriaThesis}|. You can also show your appreciation for this template by giving a \href{https://github.com/joseareia/ipleiria-thesis/stargazers}{star} on the GitHub repository. This helps increase its visibility, and you will receive notifications about the latest updates and releases. Either way, acknowledging this work, which involved significant effort and countless hours, would be greatly appreciated.




}